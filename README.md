### LLMs

Links to a few papers related to Gen AI

|Papers|
|---|
|[Transformers](transformers.pdf)|
|[Bert](bert.pdf) - Google BERT|
|[Llama2](llama.pdf) - Llama2 |
|[Tiny Llama](tiny-llama.pdf)|
|[Phi 1.5](phi-1.5.pdf) |
|[RAG](rag.pdf)|
|[Active RAG](flare.pdf)|
|[LoRa](lora.pdf)|


### Tiny LLMs
As developers you want to run and see for yourself, Tiny LLM is probably the way to go for enabling LLMs in edge sites and client devices for specialised domains and use cases.

Examples can be run for few tiny LLMs here:

|LLM|Run Instructions|
|---|---|
|Deep Seek - 1.3b parameters|```shell cd tiny-llm/deepseek <br> pip install -r requirements.txt <br> python3 run.py```|
|H2O - Danube 1.8b|```shell cd tiny-llm/h2o <br> pip install -r requirements.txt <br> python3 run.py```|
|Phi-1.5b|```shell cd tiny-llm/phi-1.5 <br> pip install -r requirements.txt <br> python3 question.py <br> python3 ui.py```|
|Tiny Llama|```shell cd tiny-llm/tiny-llama <br> pip install -r requirements.txt <br> python3 python3 question.py <br> python3 ui.py```|

